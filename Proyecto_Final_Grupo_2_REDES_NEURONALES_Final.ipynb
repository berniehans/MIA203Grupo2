{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/berniehans/MIA203Grupo2/blob/main/Proyecto_Final_Grupo_2_REDES_NEURONALES_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROYECTO FINAL\n",
        "\n",
        "# CURSO: REDES NEURONALES Y APRENDIZAJE PROFUNDO (MIA-203)\n",
        "\n",
        "# PROFESOR: ALDO CAMARGO\n",
        "\n",
        "# TEMA: SISTEMA DE IDENTIFICACION DE MEDIDAS CORPORALES A TRAVÉS DE IMAGENES USANDO CNN\n",
        "\n",
        "#Grupo #2:\n",
        "#Integrantes:\n",
        "#- Benitez Altamirano, Bernie Hans\n",
        "#- Diaz Cabrera, Alexander Gabriel\n",
        "#- Morales Ccasa, Geyson David\n",
        "#- Ramirez Ucañay, Barbarita Paula Janeth\n",
        "#- Aldo Daniel Siu Siu Ting"
      ],
      "metadata": {
        "id": "vMzsskdC8LDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso #1: Importar y activar librerias"
      ],
      "metadata": {
        "id": "dX-mXIOy5qf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, Concatenate, BatchNormalization\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import MeanAbsoluteError\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from google.colab.patches import cv2_imshow  # Importa cv2_imshow desde google.colab.patches\n",
        "from PIL import Image\n",
        "from skimage import io  # Importar la función io de skimage\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ],
      "metadata": {
        "id": "g27CzMwehtwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d75fed-7ff3-47b8-d130-37d3df41b03b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso #3: Conectar a base de datos en Google Drive"
      ],
      "metadata": {
        "id": "oFnTdQlM5ziA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Path to your zip file\n",
        "zip_path = '/content/BodyM_dataset.zip'  # Update this path\n",
        "\n",
        "# Extraction path\n",
        "extract_path = '/content/'\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n"
      ],
      "metadata": {
        "id": "EAEgtWmNh3ab"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso #4: Ver estructura de datos"
      ],
      "metadata": {
        "id": "2K9WoSoAzaeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base directory\n",
        "base_dir = '/content/BodyM_dataset'\n",
        "\n",
        "# Train data paths\n",
        "train_dir = f'{base_dir}/train'\n",
        "train_subject_to_photo_map = f'{train_dir}/subject_to_photo_map.csv'\n",
        "train_hwg_metadata = f'{train_dir}/hwg_metadata.csv'\n",
        "train_measurements = f'{train_dir}/measurements.csv'\n",
        "train_mask_dir = f'{train_dir}/mask'\n",
        "train_mask_left_dir = f'{train_dir}/mask_left'\n",
        "\n",
        "# TestA data paths\n",
        "testA_dir = f'{base_dir}/testA'\n",
        "testA_subject_to_photo_map = f'{testA_dir}/subject_to_photo_map.csv'\n",
        "testA_hwg_metadata = f'{testA_dir}/hwg_metadata.csv'\n",
        "testA_measurements = f'{testA_dir}/measurements.csv'\n",
        "testA_mask_dir = f'{testA_dir}/mask'\n",
        "testA_mask_left_dir = f'{testA_dir}/mask_left'\n",
        "\n",
        "# TestB data paths\n",
        "testB_dir = f'{base_dir}/testB'\n",
        "testB_subject_to_photo_map = f'{testB_dir}/subject_to_photo_map.csv'\n",
        "testB_hwg_metadata = f'{testB_dir}/hwg_metadata.csv'\n",
        "testB_measurements = f'{testB_dir}/measurements.csv'\n",
        "testB_mask_dir = f'{testB_dir}/mask'\n",
        "testB_mask_left_dir = f'{testB_dir}/mask_left'"
      ],
      "metadata": {
        "id": "MkYjJCUJAlHA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train data CSVs\n",
        "train_subject_to_photo_df = pd.read_csv(train_subject_to_photo_map)\n",
        "train_hwg_metadata_df = pd.read_csv(train_hwg_metadata)\n",
        "train_measurements_df = pd.read_csv(train_measurements)\n",
        "\n",
        "# Load testA data CSVs\n",
        "testA_subject_to_photo_df = pd.read_csv(testA_subject_to_photo_map)\n",
        "testA_hwg_metadata_df = pd.read_csv(testA_hwg_metadata)\n",
        "testA_measurements_df = pd.read_csv(testA_measurements)\n",
        "\n",
        "# Load testB data CSVs\n",
        "testB_subject_to_photo_df = pd.read_csv(testB_subject_to_photo_map)\n",
        "testB_hwg_metadata_df = pd.read_csv(testB_hwg_metadata)\n",
        "testB_measurements_df = pd.read_csv(testB_measurements)"
      ],
      "metadata": {
        "id": "o5TsgnxqAmZl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge data on 'subject_id' to get photo_id, height, weight, and body measurements in one DataFrame\n",
        "train_data = train_subject_to_photo_df.merge(train_hwg_metadata_df, on='subject_id').merge(train_measurements_df, on='subject_id')"
      ],
      "metadata": {
        "id": "fXYsA_qaAmn6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths for images using Google Drive paths\n",
        "train_data['frontal_image_path'] = train_mask_dir + '/' + train_data['photo_id'] + '.png'\n",
        "train_data['lateral_image_path'] = train_mask_left_dir + '/' + train_data['photo_id'] + '.png'\n",
        "\n",
        "# Define additional inputs and target labels\n",
        "additional_inputs = train_data[['height_cm', 'weight_kg']].values  # height and weight\n",
        "target_labels = train_data[['ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm',\n",
        "                            'height', 'hip', 'leg-length', 'shoulder-breadth',\n",
        "                            'shoulder-to-crotch', 'thigh', 'waist', 'wrist']].values"
      ],
      "metadata": {
        "id": "ct8w_1i3Amxq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dense, Add\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Lambda\n",
        "\n",
        "# Transformer Encoder Layer\n",
        "class TransformerEncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "# Parámetros para el Transformer\n",
        "embed_dim = 512  # Tamaño de embedding para cada token\n",
        "num_heads = 4    # Número de cabezas de atención\n",
        "ff_dim = 512     # Tamaño de la capa oculta en la red feed-forward\n",
        "\n",
        "# Imagen y extracción de características\n",
        "image_input = Input(shape=(224, 224, 2))\n",
        "resnet_base = ResNet50(include_top=False, weights=None, input_tensor=image_input)\n",
        "x = Flatten()(resnet_base.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Características adicionales (altura y peso)\n",
        "additional_input = Input(shape=(2,))\n",
        "y = Dense(64, activation='relu')(additional_input)\n",
        "\n",
        "# Combinación de características de imagen y características adicionales\n",
        "combined = Concatenate()([x, y])\n",
        "combined = Dense(embed_dim, activation=\"relu\")(combined)  # Ajusta para igualar el tamaño del embedding del Transformer\n",
        "\n",
        "# Expande dimensiones para que el tensor `combined` tenga tres dimensiones necesarias para el transformer\n",
        "combined = Lambda(lambda x: tf.expand_dims(x, axis=1))(combined)  # Añade la dimensión de secuencia\n",
        "\n",
        "# Añadir capas de Transformer Encoder\n",
        "transformer_block = TransformerEncoderLayer(embed_dim, num_heads, ff_dim)\n",
        "for _ in range(3):  # Agregando múltiples capas de Transformer\n",
        "    combined = Lambda(lambda x: transformer_block(x, training=True))(combined)\n",
        "\n",
        "# Quitar la dimensión de secuencia antes de pasar a las capas de salida\n",
        "combined = Lambda(lambda x: tf.squeeze(x, axis=1))(combined)\n",
        "\n",
        "# Capa de salida final\n",
        "z = Dense(512, activation='relu')(combined)\n",
        "z = Dropout(0.5)(z)\n",
        "output = Dense(14, activation='linear')(z)  # 14 salidas para las mediciones del cuerpo\n",
        "\n",
        "# Define el modelo final\n",
        "model = Model(inputs=[image_input, additional_input], outputs=output)\n",
        "\n",
        "\n",
        "# Define an exponential decay learning rate schedule with warmup\n",
        "initial_learning_rate = 0.001\n",
        "lr_schedule = ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=lr_schedule)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])"
      ],
      "metadata": {
        "id": "9MRSGL_JX1UR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129ca267-1975-4316-a99f-56e9e2e32808"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss',\n",
        "                              factor=0.5,\n",
        "                              patience=50,\n",
        "                              min_lr=1e-6)\n",
        "\n",
        "\n",
        "def data_generator(data, batch_size=32, target_size=(224, 224)):\n",
        "    while True:\n",
        "        for start in range(0, len(data), batch_size):\n",
        "            end = min(start + batch_size, len(data))\n",
        "            batch_data = data[start:end]\n",
        "\n",
        "            images = []\n",
        "            additional_inputs = []\n",
        "            labels = []\n",
        "\n",
        "            for _, row in batch_data.iterrows():\n",
        "                if os.path.exists(row['frontal_image_path']) and os.path.exists(row['lateral_image_path']):\n",
        "                    # Cargar y procesar las imágenes frontal y lateral\n",
        "                    frontal_image = tf.keras.preprocessing.image.load_img(row['frontal_image_path'], target_size=target_size, color_mode='grayscale')\n",
        "                    lateral_image = tf.keras.preprocessing.image.load_img(row['lateral_image_path'], target_size=target_size, color_mode='grayscale')\n",
        "\n",
        "                    # Convertir a arrays y concatenar en un input de 2 canales\n",
        "                    frontal_image = tf.keras.preprocessing.image.img_to_array(frontal_image)\n",
        "                    lateral_image = tf.keras.preprocessing.image.img_to_array(lateral_image)\n",
        "                    combined_image = np.concatenate([frontal_image, lateral_image], axis=-1)\n",
        "                    images.append(combined_image / 255.0)  # Normalizar a [0, 1]\n",
        "\n",
        "                    # Agregar height y weight como entradas adicionales\n",
        "                    additional_inputs.append([row['height_cm'], row['weight_kg']])\n",
        "\n",
        "                    # Convertir etiquetas a float32 y agregar a la lista de labels\n",
        "                    label = np.array(row[['ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm',\n",
        "                                          'height', 'hip', 'leg-length', 'shoulder-breadth',\n",
        "                                          'shoulder-to-crotch', 'thigh', 'waist', 'wrist']].values, dtype=np.float32)\n",
        "                    labels.append(label)\n",
        "\n",
        "            # Convertir listas a arrays de float32 y luego a tensores\n",
        "            images = tf.convert_to_tensor(np.array(images, dtype=np.float32))\n",
        "            additional_inputs = tf.convert_to_tensor(np.array(additional_inputs, dtype=np.float32))\n",
        "            labels = tf.convert_to_tensor(np.array(labels, dtype=np.float32))\n",
        "\n",
        "            # La salida ahora es una tupla de tuplas\n",
        "            yield (images, additional_inputs), labels\n",
        "\n",
        "# Especifica la firma de salida del generador para que coincida con los tipos producidos\n",
        "output_signature = (\n",
        "    (\n",
        "        tf.TensorSpec(shape=(None, 224, 224, 2), dtype=tf.float32),  # Para imágenes con 2 canales\n",
        "        tf.TensorSpec(shape=(None, 2), dtype=tf.float32)             # Para height y weight\n",
        "    ),\n",
        "    tf.TensorSpec(shape=(None, 14), dtype=tf.float32)                # Para las etiquetas\n",
        ")\n"
      ],
      "metadata": {
        "id": "BdkLRTyxP3uF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = next(data_generator(train_data, batch_size=2))\n",
        "print(\"Images batch shape:\", sample_data[0][0].shape)\n",
        "print(\"Additional inputs batch shape:\", sample_data[0][1].shape)\n",
        "print(\"Labels batch shape:\", sample_data[1].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_KiynIqx_n-",
        "outputId": "e4fd0fc7-41a2-4a0b-e271-b9059ea6ddaf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images batch shape: (2, 224, 224, 2)\n",
            "Additional inputs batch shape: (2, 2)\n",
            "Labels batch shape: (2, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea el dataset desde el generador\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: data_generator(train_data, batch_size=32),\n",
        "    output_signature=output_signature\n",
        ")\n",
        "\n",
        "# Entrenar el modelo usando el dataset\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=len(train_data) // 32,\n",
        "    epochs=500,\n",
        "    callbacks=[reduce_lr]\n",
        ")\n",
        "model.save(\"model_1.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANkIasOKX1Xk",
        "outputId": "7f6072ee-d8d1-4f72-911f-8addb500ae50"
      },
      "execution_count": 20,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 165ms/step - loss: 1417.9452 - mae: 23.3105 - learning_rate: 0.0010\n",
            "Epoch 2/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 164ms/step - loss: 106.0355 - mae: 7.4487 - learning_rate: 0.0010\n",
            "Epoch 3/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 74.2825 - mae: 6.0920 - learning_rate: 0.0010\n",
            "Epoch 4/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 60.2578 - mae: 5.4014 - learning_rate: 0.0010\n",
            "Epoch 5/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 55.1091 - mae: 5.0894 - learning_rate: 0.0010\n",
            "Epoch 6/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 51.4887 - mae: 4.8654 - learning_rate: 0.0010\n",
            "Epoch 7/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 48.2059 - mae: 4.7249 - learning_rate: 0.0010\n",
            "Epoch 8/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 47.2177 - mae: 4.6358 - learning_rate: 0.0010\n",
            "Epoch 9/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 44.8545 - mae: 4.5278 - learning_rate: 0.0010\n",
            "Epoch 10/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 44.7411 - mae: 4.4953 - learning_rate: 0.0010\n",
            "Epoch 11/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 45.8499 - mae: 4.5697 - learning_rate: 0.0010\n",
            "Epoch 12/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 44.6623 - mae: 4.5173 - learning_rate: 0.0010\n",
            "Epoch 13/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 43.8223 - mae: 4.4905 - learning_rate: 0.0010\n",
            "Epoch 14/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 44.6176 - mae: 4.4950 - learning_rate: 0.0010\n",
            "Epoch 15/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 42.5557 - mae: 4.3965 - learning_rate: 0.0010\n",
            "Epoch 16/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 42.5710 - mae: 4.4370 - learning_rate: 0.0010\n",
            "Epoch 17/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 42.0697 - mae: 4.3798 - learning_rate: 0.0010\n",
            "Epoch 18/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 40.0982 - mae: 4.3089 - learning_rate: 0.0010\n",
            "Epoch 19/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 40.7873 - mae: 4.3264 - learning_rate: 0.0010\n",
            "Epoch 20/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 40.3532 - mae: 4.3184 - learning_rate: 0.0010\n",
            "Epoch 21/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 39.3837 - mae: 4.2599 - learning_rate: 0.0010\n",
            "Epoch 22/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 42.4744 - mae: 4.4519 - learning_rate: 0.0010\n",
            "Epoch 23/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 38.8992 - mae: 4.2511 - learning_rate: 0.0010\n",
            "Epoch 24/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 38.5870 - mae: 4.2544 - learning_rate: 0.0010\n",
            "Epoch 25/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 38.6747 - mae: 4.2455 - learning_rate: 0.0010\n",
            "Epoch 26/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 41.2179 - mae: 4.4180 - learning_rate: 0.0010\n",
            "Epoch 27/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 39.6135 - mae: 4.2947 - learning_rate: 0.0010\n",
            "Epoch 28/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 38.3085 - mae: 4.2331 - learning_rate: 0.0010\n",
            "Epoch 29/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 39.4594 - mae: 4.2805 - learning_rate: 0.0010\n",
            "Epoch 30/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 38.7037 - mae: 4.2403 - learning_rate: 0.0010\n",
            "Epoch 31/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 40.8454 - mae: 4.3457 - learning_rate: 0.0010\n",
            "Epoch 32/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 164ms/step - loss: 37.9887 - mae: 4.2344 - learning_rate: 0.0010\n",
            "Epoch 33/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 36.6635 - mae: 4.1447 - learning_rate: 0.0010\n",
            "Epoch 34/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 37.2470 - mae: 4.1816 - learning_rate: 0.0010\n",
            "Epoch 35/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 39.1649 - mae: 4.2543 - learning_rate: 0.0010\n",
            "Epoch 36/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 38.6331 - mae: 4.2365 - learning_rate: 0.0010\n",
            "Epoch 37/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 36.9978 - mae: 4.1439 - learning_rate: 0.0010\n",
            "Epoch 38/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 38.3716 - mae: 4.2442 - learning_rate: 0.0010\n",
            "Epoch 39/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 36.4537 - mae: 4.1097 - learning_rate: 0.0010\n",
            "Epoch 40/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 37.8332 - mae: 4.2057 - learning_rate: 0.0010\n",
            "Epoch 41/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 36.4215 - mae: 4.1310 - learning_rate: 0.0010\n",
            "Epoch 42/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 37.2312 - mae: 4.2107 - learning_rate: 0.0010\n",
            "Epoch 43/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 37.3056 - mae: 4.1746 - learning_rate: 0.0010\n",
            "Epoch 44/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 37.2472 - mae: 4.1765 - learning_rate: 0.0010\n",
            "Epoch 45/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 37.5914 - mae: 4.1822 - learning_rate: 0.0010\n",
            "Epoch 46/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 35.7143 - mae: 4.1034 - learning_rate: 0.0010\n",
            "Epoch 47/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 35.8151 - mae: 4.1089 - learning_rate: 0.0010\n",
            "Epoch 48/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 38.0827 - mae: 4.2322 - learning_rate: 0.0010\n",
            "Epoch 49/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 35.1681 - mae: 4.0602 - learning_rate: 0.0010\n",
            "Epoch 50/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 36.2454 - mae: 4.0988 - learning_rate: 0.0010\n",
            "Epoch 51/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 34.7879 - mae: 4.0489 - learning_rate: 0.0010\n",
            "Epoch 52/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 35.0495 - mae: 4.0568 - learning_rate: 0.0010\n",
            "Epoch 53/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 36.4525 - mae: 4.1184 - learning_rate: 9.6000e-04\n",
            "Epoch 54/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 35.1703 - mae: 4.0562 - learning_rate: 9.6000e-04\n",
            "Epoch 55/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 35.7342 - mae: 4.1000 - learning_rate: 9.6000e-04\n",
            "Epoch 56/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 34.9113 - mae: 4.0549 - learning_rate: 9.6000e-04\n",
            "Epoch 57/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 35.1143 - mae: 4.0734 - learning_rate: 9.6000e-04\n",
            "Epoch 58/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 35.3094 - mae: 4.0610 - learning_rate: 9.6000e-04\n",
            "Epoch 59/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 35.5951 - mae: 4.0731 - learning_rate: 9.6000e-04\n",
            "Epoch 60/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 36.6936 - mae: 4.1921 - learning_rate: 9.6000e-04\n",
            "Epoch 61/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.9070 - mae: 3.9852 - learning_rate: 9.6000e-04\n",
            "Epoch 62/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 161ms/step - loss: 35.7640 - mae: 4.1130 - learning_rate: 9.6000e-04\n",
            "Epoch 63/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 35.0799 - mae: 4.0526 - learning_rate: 9.6000e-04\n",
            "Epoch 64/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 35.4827 - mae: 4.0803 - learning_rate: 9.6000e-04\n",
            "Epoch 65/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 34.3024 - mae: 3.9796 - learning_rate: 9.6000e-04\n",
            "Epoch 66/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 35.7808 - mae: 4.0911 - learning_rate: 9.6000e-04\n",
            "Epoch 67/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 34.9794 - mae: 4.0434 - learning_rate: 9.6000e-04\n",
            "Epoch 68/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 34.0322 - mae: 3.9788 - learning_rate: 9.6000e-04\n",
            "Epoch 69/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 35.4268 - mae: 4.0837 - learning_rate: 9.6000e-04\n",
            "Epoch 70/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 34.1133 - mae: 3.9763 - learning_rate: 9.6000e-04\n",
            "Epoch 71/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 33.4145 - mae: 3.9627 - learning_rate: 9.6000e-04\n",
            "Epoch 72/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.3086 - mae: 3.9595 - learning_rate: 9.6000e-04\n",
            "Epoch 73/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 34.9699 - mae: 4.0533 - learning_rate: 9.6000e-04\n",
            "Epoch 74/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 35.3655 - mae: 4.0717 - learning_rate: 9.6000e-04\n",
            "Epoch 75/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 34.3377 - mae: 4.0169 - learning_rate: 9.6000e-04\n",
            "Epoch 76/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.3867 - mae: 3.8929 - learning_rate: 9.6000e-04\n",
            "Epoch 77/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.6100 - mae: 3.9574 - learning_rate: 9.6000e-04\n",
            "Epoch 78/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 34.5189 - mae: 4.0496 - learning_rate: 9.6000e-04\n",
            "Epoch 79/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.2083 - mae: 3.9383 - learning_rate: 9.6000e-04\n",
            "Epoch 80/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.7685 - mae: 3.9980 - learning_rate: 9.6000e-04\n",
            "Epoch 81/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.8776 - mae: 3.9681 - learning_rate: 9.6000e-04\n",
            "Epoch 82/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.8169 - mae: 3.9709 - learning_rate: 9.6000e-04\n",
            "Epoch 83/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.0194 - mae: 3.9370 - learning_rate: 9.6000e-04\n",
            "Epoch 84/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 34.2129 - mae: 3.9736 - learning_rate: 9.6000e-04\n",
            "Epoch 85/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 34.1315 - mae: 3.9902 - learning_rate: 9.6000e-04\n",
            "Epoch 86/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.5289 - mae: 3.9401 - learning_rate: 9.6000e-04\n",
            "Epoch 87/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.5329 - mae: 3.9492 - learning_rate: 9.6000e-04\n",
            "Epoch 88/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 35.3322 - mae: 4.0639 - learning_rate: 9.6000e-04\n",
            "Epoch 89/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 34.4765 - mae: 4.0104 - learning_rate: 9.6000e-04\n",
            "Epoch 90/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 34.4916 - mae: 3.9904 - learning_rate: 9.6000e-04\n",
            "Epoch 91/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.8507 - mae: 3.8898 - learning_rate: 9.6000e-04\n",
            "Epoch 92/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 33.4383 - mae: 3.9676 - learning_rate: 9.6000e-04\n",
            "Epoch 93/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 34.1558 - mae: 4.0163 - learning_rate: 9.6000e-04\n",
            "Epoch 94/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 35.8633 - mae: 4.1097 - learning_rate: 9.6000e-04\n",
            "Epoch 95/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.1242 - mae: 3.9412 - learning_rate: 9.6000e-04\n",
            "Epoch 96/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 34.1342 - mae: 3.9844 - learning_rate: 9.6000e-04\n",
            "Epoch 97/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 35.2817 - mae: 4.0889 - learning_rate: 9.6000e-04\n",
            "Epoch 98/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.7735 - mae: 3.8993 - learning_rate: 9.6000e-04\n",
            "Epoch 99/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.6777 - mae: 3.9171 - learning_rate: 9.6000e-04\n",
            "Epoch 100/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 32.8251 - mae: 3.8878 - learning_rate: 9.6000e-04\n",
            "Epoch 101/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.3516 - mae: 3.9306 - learning_rate: 9.6000e-04\n",
            "Epoch 102/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 33.3079 - mae: 3.9748 - learning_rate: 9.6000e-04\n",
            "Epoch 103/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 31.1568 - mae: 3.8066 - learning_rate: 9.6000e-04\n",
            "Epoch 104/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 32.1298 - mae: 3.8854 - learning_rate: 9.6000e-04\n",
            "Epoch 105/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.1126 - mae: 3.8992 - learning_rate: 9.2160e-04\n",
            "Epoch 106/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 32.9922 - mae: 3.9247 - learning_rate: 9.2160e-04\n",
            "Epoch 107/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 32.6081 - mae: 3.9352 - learning_rate: 9.2160e-04\n",
            "Epoch 108/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.5196 - mae: 3.8857 - learning_rate: 9.2160e-04\n",
            "Epoch 109/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.4554 - mae: 3.8988 - learning_rate: 9.2160e-04\n",
            "Epoch 110/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 31.8578 - mae: 3.8444 - learning_rate: 9.2160e-04\n",
            "Epoch 111/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.8901 - mae: 3.9300 - learning_rate: 9.2160e-04\n",
            "Epoch 112/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 32.0677 - mae: 3.8610 - learning_rate: 9.2160e-04\n",
            "Epoch 113/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.4426 - mae: 3.9807 - learning_rate: 9.2160e-04\n",
            "Epoch 114/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.1455 - mae: 3.8692 - learning_rate: 9.2160e-04\n",
            "Epoch 115/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.3500 - mae: 3.7612 - learning_rate: 9.2160e-04\n",
            "Epoch 116/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 31.5594 - mae: 3.8393 - learning_rate: 9.2160e-04\n",
            "Epoch 117/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.6869 - mae: 3.8543 - learning_rate: 9.2160e-04\n",
            "Epoch 118/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.9072 - mae: 3.8463 - learning_rate: 9.2160e-04\n",
            "Epoch 119/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.5559 - mae: 3.8310 - learning_rate: 9.2160e-04\n",
            "Epoch 120/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.3955 - mae: 3.8805 - learning_rate: 9.2160e-04\n",
            "Epoch 121/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.7223 - mae: 3.8374 - learning_rate: 9.2160e-04\n",
            "Epoch 122/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.6566 - mae: 3.8539 - learning_rate: 9.2160e-04\n",
            "Epoch 123/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.6998 - mae: 3.8460 - learning_rate: 9.2160e-04\n",
            "Epoch 124/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 31.7451 - mae: 3.8427 - learning_rate: 9.2160e-04\n",
            "Epoch 125/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 31.3526 - mae: 3.8248 - learning_rate: 9.2160e-04\n",
            "Epoch 126/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 32.5141 - mae: 3.9137 - learning_rate: 9.2160e-04\n",
            "Epoch 127/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.4570 - mae: 3.8313 - learning_rate: 9.2160e-04\n",
            "Epoch 128/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.9538 - mae: 3.8673 - learning_rate: 9.2160e-04\n",
            "Epoch 129/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 32.5744 - mae: 3.9149 - learning_rate: 9.2160e-04\n",
            "Epoch 130/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.3434 - mae: 3.8298 - learning_rate: 9.2160e-04\n",
            "Epoch 131/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.2318 - mae: 3.8917 - learning_rate: 9.2160e-04\n",
            "Epoch 132/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.4460 - mae: 3.8998 - learning_rate: 9.2160e-04\n",
            "Epoch 133/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.9803 - mae: 3.9322 - learning_rate: 9.2160e-04\n",
            "Epoch 134/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.3762 - mae: 3.8223 - learning_rate: 9.2160e-04\n",
            "Epoch 135/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.6102 - mae: 3.9227 - learning_rate: 9.2160e-04\n",
            "Epoch 136/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.8627 - mae: 3.8111 - learning_rate: 9.2160e-04\n",
            "Epoch 137/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.1125 - mae: 3.8321 - learning_rate: 9.2160e-04\n",
            "Epoch 138/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.0765 - mae: 3.8920 - learning_rate: 9.2160e-04\n",
            "Epoch 139/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.6267 - mae: 3.8558 - learning_rate: 9.2160e-04\n",
            "Epoch 140/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.6317 - mae: 3.7758 - learning_rate: 9.2160e-04\n",
            "Epoch 141/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.5530 - mae: 3.8472 - learning_rate: 9.2160e-04\n",
            "Epoch 142/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 31.3854 - mae: 3.8410 - learning_rate: 9.2160e-04\n",
            "Epoch 143/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.6567 - mae: 3.7833 - learning_rate: 9.2160e-04\n",
            "Epoch 144/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.9806 - mae: 3.9683 - learning_rate: 9.2160e-04\n",
            "Epoch 145/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.2985 - mae: 3.9776 - learning_rate: 9.2160e-04\n",
            "Epoch 146/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.4086 - mae: 3.7667 - learning_rate: 9.2160e-04\n",
            "Epoch 147/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.8908 - mae: 3.8465 - learning_rate: 9.2160e-04\n",
            "Epoch 148/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.6301 - mae: 3.7909 - learning_rate: 9.2160e-04\n",
            "Epoch 149/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 161ms/step - loss: 32.1102 - mae: 3.8742 - learning_rate: 9.2160e-04\n",
            "Epoch 150/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.9232 - mae: 3.7379 - learning_rate: 9.2160e-04\n",
            "Epoch 151/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.6657 - mae: 3.9255 - learning_rate: 9.2160e-04\n",
            "Epoch 152/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.8860 - mae: 3.8723 - learning_rate: 9.2160e-04\n",
            "Epoch 153/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.5860 - mae: 3.7245 - learning_rate: 9.2160e-04\n",
            "Epoch 154/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.6535 - mae: 3.7920 - learning_rate: 9.2160e-04\n",
            "Epoch 155/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.4134 - mae: 3.7919 - learning_rate: 9.2160e-04\n",
            "Epoch 156/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.4050 - mae: 3.9802 - learning_rate: 9.2160e-04\n",
            "Epoch 157/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.8781 - mae: 3.8122 - learning_rate: 9.2160e-04\n",
            "Epoch 158/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.5030 - mae: 3.7793 - learning_rate: 8.8474e-04\n",
            "Epoch 159/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 31.8845 - mae: 3.8744 - learning_rate: 8.8474e-04\n",
            "Epoch 160/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.5589 - mae: 3.8308 - learning_rate: 8.8474e-04\n",
            "Epoch 161/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 30.1417 - mae: 3.7701 - learning_rate: 8.8474e-04\n",
            "Epoch 162/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.3914 - mae: 3.7904 - learning_rate: 8.8474e-04\n",
            "Epoch 163/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 28.6677 - mae: 3.6656 - learning_rate: 8.8474e-04\n",
            "Epoch 164/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.3451 - mae: 3.7794 - learning_rate: 8.8474e-04\n",
            "Epoch 165/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.7621 - mae: 3.7891 - learning_rate: 8.8474e-04\n",
            "Epoch 166/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.5920 - mae: 3.7921 - learning_rate: 8.8474e-04\n",
            "Epoch 167/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.2107 - mae: 3.7673 - learning_rate: 8.8474e-04\n",
            "Epoch 168/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.6215 - mae: 3.8379 - learning_rate: 8.8474e-04\n",
            "Epoch 169/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.7974 - mae: 3.8771 - learning_rate: 8.8474e-04\n",
            "Epoch 170/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 32.6526 - mae: 3.9306 - learning_rate: 8.8474e-04\n",
            "Epoch 171/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.0113 - mae: 3.8684 - learning_rate: 8.8474e-04\n",
            "Epoch 172/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.9883 - mae: 3.7502 - learning_rate: 8.8474e-04\n",
            "Epoch 173/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.1924 - mae: 3.7720 - learning_rate: 8.8474e-04\n",
            "Epoch 174/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.5317 - mae: 3.8896 - learning_rate: 8.8474e-04\n",
            "Epoch 175/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 31.8688 - mae: 3.8804 - learning_rate: 8.8474e-04\n",
            "Epoch 176/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 31.7569 - mae: 3.8530 - learning_rate: 8.8474e-04\n",
            "Epoch 177/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 31.1877 - mae: 3.8138 - learning_rate: 8.8474e-04\n",
            "Epoch 178/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.1937 - mae: 3.9378 - learning_rate: 8.8474e-04\n",
            "Epoch 179/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 33.2851 - mae: 3.9496 - learning_rate: 8.8474e-04\n",
            "Epoch 180/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.0647 - mae: 3.9589 - learning_rate: 8.8474e-04\n",
            "Epoch 181/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.8663 - mae: 3.9190 - learning_rate: 8.8474e-04\n",
            "Epoch 182/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.8369 - mae: 3.8591 - learning_rate: 8.8474e-04\n",
            "Epoch 183/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.7420 - mae: 3.7975 - learning_rate: 8.8474e-04\n",
            "Epoch 184/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.3088 - mae: 3.8282 - learning_rate: 8.8474e-04\n",
            "Epoch 185/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 31.1687 - mae: 3.8070 - learning_rate: 8.8474e-04\n",
            "Epoch 186/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.9774 - mae: 3.8157 - learning_rate: 8.8474e-04\n",
            "Epoch 187/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 31.7007 - mae: 3.8310 - learning_rate: 8.8474e-04\n",
            "Epoch 188/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 32.7098 - mae: 3.8862 - learning_rate: 8.8474e-04\n",
            "Epoch 189/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.8145 - mae: 3.8316 - learning_rate: 8.8474e-04\n",
            "Epoch 190/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 33.8945 - mae: 3.9977 - learning_rate: 8.8474e-04\n",
            "Epoch 191/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.9841 - mae: 3.8758 - learning_rate: 8.8474e-04\n",
            "Epoch 192/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 33.2934 - mae: 3.9349 - learning_rate: 8.8474e-04\n",
            "Epoch 193/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.9423 - mae: 3.7875 - learning_rate: 8.8474e-04\n",
            "Epoch 194/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.4658 - mae: 3.8291 - learning_rate: 8.8474e-04\n",
            "Epoch 195/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 30.1944 - mae: 3.7734 - learning_rate: 8.8474e-04\n",
            "Epoch 196/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 31.5676 - mae: 3.8319 - learning_rate: 8.8474e-04\n",
            "Epoch 197/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.6318 - mae: 3.7323 - learning_rate: 8.8474e-04\n",
            "Epoch 198/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.1232 - mae: 3.8067 - learning_rate: 8.8474e-04\n",
            "Epoch 199/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.6420 - mae: 3.8624 - learning_rate: 8.8474e-04\n",
            "Epoch 200/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.7959 - mae: 3.7326 - learning_rate: 8.8474e-04\n",
            "Epoch 201/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 30.3640 - mae: 3.7793 - learning_rate: 8.8474e-04\n",
            "Epoch 202/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.9946 - mae: 3.8932 - learning_rate: 8.8474e-04\n",
            "Epoch 203/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 30.5239 - mae: 3.7785 - learning_rate: 8.8474e-04\n",
            "Epoch 204/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.8416 - mae: 3.7152 - learning_rate: 8.8474e-04\n",
            "Epoch 205/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.2943 - mae: 3.8545 - learning_rate: 8.8474e-04\n",
            "Epoch 206/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.4874 - mae: 3.7770 - learning_rate: 8.8474e-04\n",
            "Epoch 207/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.5385 - mae: 3.7053 - learning_rate: 8.8474e-04\n",
            "Epoch 208/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.6433 - mae: 3.7906 - learning_rate: 8.8474e-04\n",
            "Epoch 209/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.3479 - mae: 3.7899 - learning_rate: 8.8474e-04\n",
            "Epoch 210/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.9297 - mae: 3.6706 - learning_rate: 8.4935e-04\n",
            "Epoch 211/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.5438 - mae: 3.7029 - learning_rate: 8.4935e-04\n",
            "Epoch 212/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 30.7621 - mae: 3.7912 - learning_rate: 8.4935e-04\n",
            "Epoch 213/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 31.8113 - mae: 3.8567 - learning_rate: 8.4935e-04\n",
            "Epoch 214/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.2214 - mae: 3.7329 - learning_rate: 8.4935e-04\n",
            "Epoch 215/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 30.7955 - mae: 3.7788 - learning_rate: 8.4935e-04\n",
            "Epoch 216/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 29.9078 - mae: 3.7291 - learning_rate: 8.4935e-04\n",
            "Epoch 217/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 29.6738 - mae: 3.7393 - learning_rate: 8.4935e-04\n",
            "Epoch 218/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.9385 - mae: 3.8123 - learning_rate: 8.4935e-04\n",
            "Epoch 219/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.9165 - mae: 3.7901 - learning_rate: 8.4935e-04\n",
            "Epoch 220/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.2309 - mae: 3.8061 - learning_rate: 8.4935e-04\n",
            "Epoch 221/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 30.4782 - mae: 3.7509 - learning_rate: 8.4935e-04\n",
            "Epoch 222/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 29.4194 - mae: 3.7055 - learning_rate: 8.4935e-04\n",
            "Epoch 223/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 29.9686 - mae: 3.7456 - learning_rate: 8.4935e-04\n",
            "Epoch 224/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 29.8394 - mae: 3.7518 - learning_rate: 8.4935e-04\n",
            "Epoch 225/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.2543 - mae: 3.6251 - learning_rate: 8.4935e-04\n",
            "Epoch 226/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 32.2754 - mae: 3.8928 - learning_rate: 8.4935e-04\n",
            "Epoch 227/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.5918 - mae: 3.7207 - learning_rate: 8.4935e-04\n",
            "Epoch 228/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.8350 - mae: 3.7259 - learning_rate: 8.4935e-04\n",
            "Epoch 229/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.6530 - mae: 3.5864 - learning_rate: 8.4935e-04\n",
            "Epoch 230/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.2810 - mae: 3.6343 - learning_rate: 8.4935e-04\n",
            "Epoch 231/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.3992 - mae: 3.7234 - learning_rate: 8.4935e-04\n",
            "Epoch 232/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.3675 - mae: 3.6462 - learning_rate: 8.4935e-04\n",
            "Epoch 233/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 30.0955 - mae: 3.7829 - learning_rate: 8.4935e-04\n",
            "Epoch 234/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.7118 - mae: 3.6704 - learning_rate: 8.4935e-04\n",
            "Epoch 235/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.3418 - mae: 3.6464 - learning_rate: 8.4935e-04\n",
            "Epoch 236/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 31.3504 - mae: 3.8592 - learning_rate: 8.4935e-04\n",
            "Epoch 237/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.4997 - mae: 3.7053 - learning_rate: 8.4935e-04\n",
            "Epoch 238/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.4805 - mae: 3.7374 - learning_rate: 8.4935e-04\n",
            "Epoch 239/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.8266 - mae: 3.6950 - learning_rate: 8.4935e-04\n",
            "Epoch 240/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.6715 - mae: 3.7411 - learning_rate: 8.4935e-04\n",
            "Epoch 241/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 30.1381 - mae: 3.7478 - learning_rate: 8.4935e-04\n",
            "Epoch 242/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.3877 - mae: 3.7268 - learning_rate: 8.4935e-04\n",
            "Epoch 243/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.1973 - mae: 3.6335 - learning_rate: 8.4935e-04\n",
            "Epoch 244/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.0291 - mae: 3.6731 - learning_rate: 8.4935e-04\n",
            "Epoch 245/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 29.5749 - mae: 3.7192 - learning_rate: 8.4935e-04\n",
            "Epoch 246/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.6503 - mae: 3.6718 - learning_rate: 8.4935e-04\n",
            "Epoch 247/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.7412 - mae: 3.7376 - learning_rate: 8.4935e-04\n",
            "Epoch 248/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.4044 - mae: 3.7030 - learning_rate: 8.4935e-04\n",
            "Epoch 249/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.0206 - mae: 3.6725 - learning_rate: 8.4935e-04\n",
            "Epoch 250/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.4760 - mae: 3.6445 - learning_rate: 8.4935e-04\n",
            "Epoch 251/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.8788 - mae: 3.7437 - learning_rate: 8.4935e-04\n",
            "Epoch 252/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.4954 - mae: 3.7297 - learning_rate: 8.4935e-04\n",
            "Epoch 253/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 29.9838 - mae: 3.7670 - learning_rate: 8.4935e-04\n",
            "Epoch 254/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 29.2047 - mae: 3.6932 - learning_rate: 8.4935e-04\n",
            "Epoch 255/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.4041 - mae: 3.7277 - learning_rate: 8.4935e-04\n",
            "Epoch 256/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.5859 - mae: 3.6543 - learning_rate: 8.4935e-04\n",
            "Epoch 257/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.9380 - mae: 3.7451 - learning_rate: 8.4935e-04\n",
            "Epoch 258/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.1489 - mae: 3.7066 - learning_rate: 8.4935e-04\n",
            "Epoch 259/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.2996 - mae: 3.7345 - learning_rate: 8.4935e-04\n",
            "Epoch 260/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 28.1906 - mae: 3.6119 - learning_rate: 8.4935e-04\n",
            "Epoch 261/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 28.7299 - mae: 3.6560 - learning_rate: 8.4935e-04\n",
            "Epoch 262/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 28.5280 - mae: 3.6641 - learning_rate: 8.1537e-04\n",
            "Epoch 263/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 29.4382 - mae: 3.7385 - learning_rate: 8.1537e-04\n",
            "Epoch 264/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.4062 - mae: 3.6459 - learning_rate: 8.1537e-04\n",
            "Epoch 265/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.9442 - mae: 3.5919 - learning_rate: 8.1537e-04\n",
            "Epoch 266/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.8922 - mae: 3.6217 - learning_rate: 8.1537e-04\n",
            "Epoch 267/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.4929 - mae: 3.6562 - learning_rate: 8.1537e-04\n",
            "Epoch 268/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 28.4951 - mae: 3.6544 - learning_rate: 8.1537e-04\n",
            "Epoch 269/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 28.5601 - mae: 3.6700 - learning_rate: 8.1537e-04\n",
            "Epoch 270/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.5168 - mae: 3.5895 - learning_rate: 8.1537e-04\n",
            "Epoch 271/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.6970 - mae: 3.6002 - learning_rate: 8.1537e-04\n",
            "Epoch 272/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.5747 - mae: 3.6998 - learning_rate: 8.1537e-04\n",
            "Epoch 273/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.6836 - mae: 3.6094 - learning_rate: 8.1537e-04\n",
            "Epoch 274/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.9076 - mae: 3.6822 - learning_rate: 8.1537e-04\n",
            "Epoch 275/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.2005 - mae: 3.7038 - learning_rate: 8.1537e-04\n",
            "Epoch 276/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.3454 - mae: 3.6527 - learning_rate: 8.1537e-04\n",
            "Epoch 277/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.3723 - mae: 3.5765 - learning_rate: 8.1537e-04\n",
            "Epoch 278/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 28.7520 - mae: 3.6799 - learning_rate: 8.1537e-04\n",
            "Epoch 279/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 28.7605 - mae: 3.6586 - learning_rate: 8.1537e-04\n",
            "Epoch 280/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.6797 - mae: 3.5637 - learning_rate: 8.1537e-04\n",
            "Epoch 281/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.6792 - mae: 3.6754 - learning_rate: 8.1537e-04\n",
            "Epoch 282/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 28.5552 - mae: 3.6710 - learning_rate: 8.1537e-04\n",
            "Epoch 283/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.5485 - mae: 3.6742 - learning_rate: 8.1537e-04\n",
            "Epoch 284/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.9131 - mae: 3.6254 - learning_rate: 8.1537e-04\n",
            "Epoch 285/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.8919 - mae: 3.6007 - learning_rate: 8.1537e-04\n",
            "Epoch 286/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 161ms/step - loss: 29.6708 - mae: 3.7540 - learning_rate: 8.1537e-04\n",
            "Epoch 287/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 28.6413 - mae: 3.6474 - learning_rate: 8.1537e-04\n",
            "Epoch 288/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 28.7576 - mae: 3.6810 - learning_rate: 8.1537e-04\n",
            "Epoch 289/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 29.8712 - mae: 3.7425 - learning_rate: 8.1537e-04\n",
            "Epoch 290/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 29.8715 - mae: 3.7658 - learning_rate: 8.1537e-04\n",
            "Epoch 291/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 28.9048 - mae: 3.6853 - learning_rate: 8.1537e-04\n",
            "Epoch 292/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 161ms/step - loss: 26.6142 - mae: 3.5290 - learning_rate: 8.1537e-04\n",
            "Epoch 293/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.6552 - mae: 3.5636 - learning_rate: 8.1537e-04\n",
            "Epoch 294/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.0616 - mae: 3.6188 - learning_rate: 8.1537e-04\n",
            "Epoch 295/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.9492 - mae: 3.5714 - learning_rate: 8.1537e-04\n",
            "Epoch 296/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.7058 - mae: 3.6577 - learning_rate: 8.1537e-04\n",
            "Epoch 297/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.5967 - mae: 3.5702 - learning_rate: 8.1537e-04\n",
            "Epoch 298/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.1076 - mae: 3.5460 - learning_rate: 8.1537e-04\n",
            "Epoch 299/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.6891 - mae: 3.5529 - learning_rate: 8.1537e-04\n",
            "Epoch 300/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.6721 - mae: 3.5923 - learning_rate: 8.1537e-04\n",
            "Epoch 301/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.5958 - mae: 3.6534 - learning_rate: 8.1537e-04\n",
            "Epoch 302/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.3799 - mae: 3.4996 - learning_rate: 8.1537e-04\n",
            "Epoch 303/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.0620 - mae: 3.5493 - learning_rate: 8.1537e-04\n",
            "Epoch 304/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 161ms/step - loss: 27.7652 - mae: 3.5997 - learning_rate: 8.1537e-04\n",
            "Epoch 305/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.6906 - mae: 3.5213 - learning_rate: 8.1537e-04\n",
            "Epoch 306/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.9477 - mae: 3.4677 - learning_rate: 8.1537e-04\n",
            "Epoch 307/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.7240 - mae: 3.6166 - learning_rate: 8.1537e-04\n",
            "Epoch 308/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.1326 - mae: 3.5424 - learning_rate: 8.1537e-04\n",
            "Epoch 309/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.4022 - mae: 3.5842 - learning_rate: 8.1537e-04\n",
            "Epoch 310/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.2250 - mae: 3.5364 - learning_rate: 8.1537e-04\n",
            "Epoch 311/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.3424 - mae: 3.5611 - learning_rate: 8.1537e-04\n",
            "Epoch 312/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.9222 - mae: 3.5445 - learning_rate: 8.1537e-04\n",
            "Epoch 313/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.4916 - mae: 3.5052 - learning_rate: 8.1537e-04\n",
            "Epoch 314/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.7239 - mae: 3.5414 - learning_rate: 8.1537e-04\n",
            "Epoch 315/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.3750 - mae: 3.4947 - learning_rate: 7.8276e-04\n",
            "Epoch 316/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.9220 - mae: 3.6115 - learning_rate: 7.8276e-04\n",
            "Epoch 317/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.2120 - mae: 3.5568 - learning_rate: 7.8276e-04\n",
            "Epoch 318/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.9050 - mae: 3.5954 - learning_rate: 7.8276e-04\n",
            "Epoch 319/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.5640 - mae: 3.4625 - learning_rate: 7.8276e-04\n",
            "Epoch 320/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.2094 - mae: 3.5572 - learning_rate: 7.8276e-04\n",
            "Epoch 321/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.1141 - mae: 3.5082 - learning_rate: 7.8276e-04\n",
            "Epoch 322/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.7169 - mae: 3.5226 - learning_rate: 7.8276e-04\n",
            "Epoch 323/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.4159 - mae: 3.5828 - learning_rate: 7.8276e-04\n",
            "Epoch 324/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.3840 - mae: 3.5500 - learning_rate: 7.8276e-04\n",
            "Epoch 325/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.7787 - mae: 3.6014 - learning_rate: 7.8276e-04\n",
            "Epoch 326/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.9859 - mae: 3.5356 - learning_rate: 7.8276e-04\n",
            "Epoch 327/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.0924 - mae: 3.5328 - learning_rate: 7.8276e-04\n",
            "Epoch 328/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.9597 - mae: 3.5411 - learning_rate: 7.8276e-04\n",
            "Epoch 329/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.2845 - mae: 3.5723 - learning_rate: 7.8276e-04\n",
            "Epoch 330/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.3800 - mae: 3.5009 - learning_rate: 7.8276e-04\n",
            "Epoch 331/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.7882 - mae: 3.5242 - learning_rate: 7.8276e-04\n",
            "Epoch 332/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.8339 - mae: 3.5411 - learning_rate: 7.8276e-04\n",
            "Epoch 333/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.0986 - mae: 3.4839 - learning_rate: 7.8276e-04\n",
            "Epoch 334/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.1377 - mae: 3.5635 - learning_rate: 7.8276e-04\n",
            "Epoch 335/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.6224 - mae: 3.5944 - learning_rate: 7.8276e-04\n",
            "Epoch 336/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.7716 - mae: 3.5041 - learning_rate: 7.8276e-04\n",
            "Epoch 337/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.7863 - mae: 3.5074 - learning_rate: 7.8276e-04\n",
            "Epoch 338/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.4733 - mae: 3.5790 - learning_rate: 7.8276e-04\n",
            "Epoch 339/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 25.2751 - mae: 3.4187 - learning_rate: 7.8276e-04\n",
            "Epoch 340/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.2322 - mae: 3.4783 - learning_rate: 7.8276e-04\n",
            "Epoch 341/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.3797 - mae: 3.4837 - learning_rate: 7.8276e-04\n",
            "Epoch 342/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.9129 - mae: 3.5145 - learning_rate: 7.8276e-04\n",
            "Epoch 343/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.6884 - mae: 3.5219 - learning_rate: 7.8276e-04\n",
            "Epoch 344/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.3413 - mae: 3.4769 - learning_rate: 7.8276e-04\n",
            "Epoch 345/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.8060 - mae: 3.5090 - learning_rate: 7.8276e-04\n",
            "Epoch 346/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.2360 - mae: 3.5556 - learning_rate: 7.8276e-04\n",
            "Epoch 347/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.1035 - mae: 3.6220 - learning_rate: 7.8276e-04\n",
            "Epoch 348/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.9339 - mae: 3.4483 - learning_rate: 7.8276e-04\n",
            "Epoch 349/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.3699 - mae: 3.4366 - learning_rate: 7.8276e-04\n",
            "Epoch 350/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.3493 - mae: 3.5025 - learning_rate: 7.8276e-04\n",
            "Epoch 351/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.6383 - mae: 3.4386 - learning_rate: 7.8276e-04\n",
            "Epoch 352/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.6039 - mae: 3.4467 - learning_rate: 7.8276e-04\n",
            "Epoch 353/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.2559 - mae: 3.5019 - learning_rate: 7.8276e-04\n",
            "Epoch 354/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.8599 - mae: 3.4118 - learning_rate: 7.8276e-04\n",
            "Epoch 355/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.7634 - mae: 3.5057 - learning_rate: 7.8276e-04\n",
            "Epoch 356/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.1046 - mae: 3.4662 - learning_rate: 7.8276e-04\n",
            "Epoch 357/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 25.7721 - mae: 3.4812 - learning_rate: 7.8276e-04\n",
            "Epoch 358/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.7832 - mae: 3.5238 - learning_rate: 7.8276e-04\n",
            "Epoch 359/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.0641 - mae: 3.5396 - learning_rate: 7.8276e-04\n",
            "Epoch 360/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.5237 - mae: 3.4514 - learning_rate: 7.8276e-04\n",
            "Epoch 361/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 25.9045 - mae: 3.4913 - learning_rate: 7.8276e-04\n",
            "Epoch 362/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.3021 - mae: 3.5442 - learning_rate: 7.8276e-04\n",
            "Epoch 363/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.1366 - mae: 3.5624 - learning_rate: 7.8276e-04\n",
            "Epoch 364/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.4643 - mae: 3.5874 - learning_rate: 7.8276e-04\n",
            "Epoch 365/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.5358 - mae: 3.5034 - learning_rate: 7.8276e-04\n",
            "Epoch 366/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.7423 - mae: 3.5193 - learning_rate: 7.8276e-04\n",
            "Epoch 367/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.4229 - mae: 3.5604 - learning_rate: 7.5145e-04\n",
            "Epoch 368/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.3922 - mae: 3.5492 - learning_rate: 7.5145e-04\n",
            "Epoch 369/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.1941 - mae: 3.5116 - learning_rate: 7.5145e-04\n",
            "Epoch 370/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.3073 - mae: 3.6069 - learning_rate: 7.5145e-04\n",
            "Epoch 371/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 28.7241 - mae: 3.6439 - learning_rate: 7.5145e-04\n",
            "Epoch 372/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.1690 - mae: 3.5455 - learning_rate: 7.5145e-04\n",
            "Epoch 373/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 28.1760 - mae: 3.6362 - learning_rate: 7.5145e-04\n",
            "Epoch 374/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.0991 - mae: 3.5558 - learning_rate: 7.5145e-04\n",
            "Epoch 375/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.4195 - mae: 3.5698 - learning_rate: 7.5145e-04\n",
            "Epoch 376/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.1465 - mae: 3.4688 - learning_rate: 7.5145e-04\n",
            "Epoch 377/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.4585 - mae: 3.4944 - learning_rate: 7.5145e-04\n",
            "Epoch 378/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.5591 - mae: 3.5133 - learning_rate: 7.5145e-04\n",
            "Epoch 379/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.0111 - mae: 3.5203 - learning_rate: 7.5145e-04\n",
            "Epoch 380/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.1909 - mae: 3.5297 - learning_rate: 7.5145e-04\n",
            "Epoch 381/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 28.1792 - mae: 3.6304 - learning_rate: 7.5145e-04\n",
            "Epoch 382/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.3649 - mae: 3.5537 - learning_rate: 7.5145e-04\n",
            "Epoch 383/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 25.0201 - mae: 3.3954 - learning_rate: 7.5145e-04\n",
            "Epoch 384/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.7390 - mae: 3.5700 - learning_rate: 7.5145e-04\n",
            "Epoch 385/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.3255 - mae: 3.5331 - learning_rate: 7.5145e-04\n",
            "Epoch 386/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.1764 - mae: 3.4914 - learning_rate: 7.5145e-04\n",
            "Epoch 387/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.7225 - mae: 3.4954 - learning_rate: 7.5145e-04\n",
            "Epoch 388/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.1631 - mae: 3.4795 - learning_rate: 7.5145e-04\n",
            "Epoch 389/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.4688 - mae: 3.4836 - learning_rate: 7.5145e-04\n",
            "Epoch 390/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.9695 - mae: 3.4878 - learning_rate: 7.5145e-04\n",
            "Epoch 391/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.4589 - mae: 3.4923 - learning_rate: 7.5145e-04\n",
            "Epoch 392/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.3422 - mae: 3.5580 - learning_rate: 7.5145e-04\n",
            "Epoch 393/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.2052 - mae: 3.5145 - learning_rate: 7.5145e-04\n",
            "Epoch 394/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.8905 - mae: 3.4497 - learning_rate: 7.5145e-04\n",
            "Epoch 395/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.6322 - mae: 3.5863 - learning_rate: 7.5145e-04\n",
            "Epoch 396/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.8639 - mae: 3.4620 - learning_rate: 7.5145e-04\n",
            "Epoch 397/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.1555 - mae: 3.5428 - learning_rate: 7.5145e-04\n",
            "Epoch 398/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.1797 - mae: 3.4923 - learning_rate: 7.5145e-04\n",
            "Epoch 399/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.3823 - mae: 3.5007 - learning_rate: 7.5145e-04\n",
            "Epoch 400/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.0870 - mae: 3.4553 - learning_rate: 7.5145e-04\n",
            "Epoch 401/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.5898 - mae: 3.5100 - learning_rate: 7.5145e-04\n",
            "Epoch 402/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.7337 - mae: 3.4353 - learning_rate: 7.5145e-04\n",
            "Epoch 403/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.0569 - mae: 3.4465 - learning_rate: 7.5145e-04\n",
            "Epoch 404/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 25.5912 - mae: 3.4453 - learning_rate: 7.5145e-04\n",
            "Epoch 405/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.5285 - mae: 3.5895 - learning_rate: 7.5145e-04\n",
            "Epoch 406/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.3039 - mae: 3.4930 - learning_rate: 7.5145e-04\n",
            "Epoch 407/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 25.4342 - mae: 3.4222 - learning_rate: 7.5145e-04\n",
            "Epoch 408/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.8193 - mae: 3.5575 - learning_rate: 7.5145e-04\n",
            "Epoch 409/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.8048 - mae: 3.4569 - learning_rate: 7.5145e-04\n",
            "Epoch 410/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.4048 - mae: 3.4775 - learning_rate: 7.5145e-04\n",
            "Epoch 411/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.5526 - mae: 3.5008 - learning_rate: 7.5145e-04\n",
            "Epoch 412/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.1310 - mae: 3.4785 - learning_rate: 7.5145e-04\n",
            "Epoch 413/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.3665 - mae: 3.5665 - learning_rate: 7.5145e-04\n",
            "Epoch 414/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.5586 - mae: 3.5741 - learning_rate: 7.5145e-04\n",
            "Epoch 415/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.0007 - mae: 3.4905 - learning_rate: 7.5145e-04\n",
            "Epoch 416/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 27.3107 - mae: 3.5542 - learning_rate: 7.5145e-04\n",
            "Epoch 417/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.2734 - mae: 3.4807 - learning_rate: 7.5145e-04\n",
            "Epoch 418/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.0810 - mae: 3.4714 - learning_rate: 7.5145e-04\n",
            "Epoch 419/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.1115 - mae: 3.4005 - learning_rate: 7.2139e-04\n",
            "Epoch 420/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.5986 - mae: 3.4375 - learning_rate: 7.2139e-04\n",
            "Epoch 421/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.3512 - mae: 3.4131 - learning_rate: 7.2139e-04\n",
            "Epoch 422/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.7546 - mae: 3.3944 - learning_rate: 7.2139e-04\n",
            "Epoch 423/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.8293 - mae: 3.4510 - learning_rate: 7.2139e-04\n",
            "Epoch 424/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.0192 - mae: 3.4579 - learning_rate: 7.2139e-04\n",
            "Epoch 425/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.7358 - mae: 3.4487 - learning_rate: 7.2139e-04\n",
            "Epoch 426/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 27.0977 - mae: 3.5309 - learning_rate: 7.2139e-04\n",
            "Epoch 427/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.1434 - mae: 3.4039 - learning_rate: 7.2139e-04\n",
            "Epoch 428/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 25.5987 - mae: 3.4220 - learning_rate: 7.2139e-04\n",
            "Epoch 429/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.7111 - mae: 3.4395 - learning_rate: 7.2139e-04\n",
            "Epoch 430/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.5898 - mae: 3.4346 - learning_rate: 7.2139e-04\n",
            "Epoch 431/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.6121 - mae: 3.4492 - learning_rate: 7.2139e-04\n",
            "Epoch 432/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.0071 - mae: 3.3919 - learning_rate: 7.2139e-04\n",
            "Epoch 433/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 25.1673 - mae: 3.4184 - learning_rate: 7.2139e-04\n",
            "Epoch 434/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.7926 - mae: 3.4437 - learning_rate: 7.2139e-04\n",
            "Epoch 435/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.9298 - mae: 3.3939 - learning_rate: 7.2139e-04\n",
            "Epoch 436/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 25.1174 - mae: 3.4128 - learning_rate: 7.2139e-04\n",
            "Epoch 437/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.9375 - mae: 3.4857 - learning_rate: 7.2139e-04\n",
            "Epoch 438/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.4171 - mae: 3.4199 - learning_rate: 7.2139e-04\n",
            "Epoch 439/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.6705 - mae: 3.5229 - learning_rate: 7.2139e-04\n",
            "Epoch 440/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.1709 - mae: 3.5033 - learning_rate: 7.2139e-04\n",
            "Epoch 441/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.2768 - mae: 3.4117 - learning_rate: 7.2139e-04\n",
            "Epoch 442/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.2671 - mae: 3.5189 - learning_rate: 7.2139e-04\n",
            "Epoch 443/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.0728 - mae: 3.3969 - learning_rate: 7.2139e-04\n",
            "Epoch 444/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.0174 - mae: 3.4564 - learning_rate: 7.2139e-04\n",
            "Epoch 445/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.5786 - mae: 3.3532 - learning_rate: 7.2139e-04\n",
            "Epoch 446/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 23.9821 - mae: 3.3356 - learning_rate: 7.2139e-04\n",
            "Epoch 447/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.3321 - mae: 3.4467 - learning_rate: 7.2139e-04\n",
            "Epoch 448/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.1016 - mae: 3.3966 - learning_rate: 7.2139e-04\n",
            "Epoch 449/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.2669 - mae: 3.3491 - learning_rate: 7.2139e-04\n",
            "Epoch 450/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 24.1808 - mae: 3.3428 - learning_rate: 7.2139e-04\n",
            "Epoch 451/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.3689 - mae: 3.4453 - learning_rate: 7.2139e-04\n",
            "Epoch 452/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 25.2526 - mae: 3.4164 - learning_rate: 7.2139e-04\n",
            "Epoch 453/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 25.2404 - mae: 3.4025 - learning_rate: 7.2139e-04\n",
            "Epoch 454/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.0497 - mae: 3.4005 - learning_rate: 7.2139e-04\n",
            "Epoch 455/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.7017 - mae: 3.3840 - learning_rate: 7.2139e-04\n",
            "Epoch 456/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.4233 - mae: 3.3603 - learning_rate: 7.2139e-04\n",
            "Epoch 457/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.5381 - mae: 3.4214 - learning_rate: 7.2139e-04\n",
            "Epoch 458/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.4684 - mae: 3.4277 - learning_rate: 7.2139e-04\n",
            "Epoch 459/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 25.4948 - mae: 3.4466 - learning_rate: 7.2139e-04\n",
            "Epoch 460/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.2959 - mae: 3.4080 - learning_rate: 7.2139e-04\n",
            "Epoch 461/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 25.4495 - mae: 3.4187 - learning_rate: 7.2139e-04\n",
            "Epoch 462/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 24.4584 - mae: 3.3694 - learning_rate: 7.2139e-04\n",
            "Epoch 463/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 24.6929 - mae: 3.3759 - learning_rate: 7.2139e-04\n",
            "Epoch 464/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 24.9878 - mae: 3.3852 - learning_rate: 7.2139e-04\n",
            "Epoch 465/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.7242 - mae: 3.3697 - learning_rate: 7.2139e-04\n",
            "Epoch 466/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 25.4959 - mae: 3.4123 - learning_rate: 7.2139e-04\n",
            "Epoch 467/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.3979 - mae: 3.3422 - learning_rate: 7.2139e-04\n",
            "Epoch 468/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.0271 - mae: 3.3278 - learning_rate: 7.2139e-04\n",
            "Epoch 469/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 26.1689 - mae: 3.4609 - learning_rate: 7.2139e-04\n",
            "Epoch 470/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.8889 - mae: 3.3737 - learning_rate: 7.2139e-04\n",
            "Epoch 471/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 26.0522 - mae: 3.4769 - learning_rate: 7.2139e-04\n",
            "Epoch 472/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.7479 - mae: 3.4877 - learning_rate: 6.9253e-04\n",
            "Epoch 473/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.5168 - mae: 3.3945 - learning_rate: 6.9253e-04\n",
            "Epoch 474/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.0912 - mae: 3.3232 - learning_rate: 6.9253e-04\n",
            "Epoch 475/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 23.8712 - mae: 3.3311 - learning_rate: 6.9253e-04\n",
            "Epoch 476/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 25.5533 - mae: 3.4187 - learning_rate: 6.9253e-04\n",
            "Epoch 477/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.9111 - mae: 3.3811 - learning_rate: 6.9253e-04\n",
            "Epoch 478/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 24.5259 - mae: 3.3448 - learning_rate: 6.9253e-04\n",
            "Epoch 479/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 24.0341 - mae: 3.3236 - learning_rate: 6.9253e-04\n",
            "Epoch 480/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 24.5416 - mae: 3.3618 - learning_rate: 6.9253e-04\n",
            "Epoch 481/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 23.8562 - mae: 3.3074 - learning_rate: 6.9253e-04\n",
            "Epoch 482/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 23.7365 - mae: 3.2964 - learning_rate: 6.9253e-04\n",
            "Epoch 483/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 24.5926 - mae: 3.3637 - learning_rate: 6.9253e-04\n",
            "Epoch 484/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.8650 - mae: 3.3754 - learning_rate: 6.9253e-04\n",
            "Epoch 485/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 24.7217 - mae: 3.3633 - learning_rate: 6.9253e-04\n",
            "Epoch 486/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.0080 - mae: 3.3817 - learning_rate: 6.9253e-04\n",
            "Epoch 487/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 24.4887 - mae: 3.3342 - learning_rate: 6.9253e-04\n",
            "Epoch 488/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 23.9837 - mae: 3.3320 - learning_rate: 6.9253e-04\n",
            "Epoch 489/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 23.5707 - mae: 3.2827 - learning_rate: 6.9253e-04\n",
            "Epoch 490/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 25.4578 - mae: 3.4190 - learning_rate: 6.9253e-04\n",
            "Epoch 491/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 23.6932 - mae: 3.3278 - learning_rate: 6.9253e-04\n",
            "Epoch 492/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 24.0606 - mae: 3.2941 - learning_rate: 6.9253e-04\n",
            "Epoch 493/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 23.5813 - mae: 3.2875 - learning_rate: 6.9253e-04\n",
            "Epoch 494/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 23.7429 - mae: 3.2913 - learning_rate: 6.9253e-04\n",
            "Epoch 495/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 24.5347 - mae: 3.3415 - learning_rate: 6.9253e-04\n",
            "Epoch 496/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 23.7430 - mae: 3.3090 - learning_rate: 6.9253e-04\n",
            "Epoch 497/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 24.3543 - mae: 3.3577 - learning_rate: 6.9253e-04\n",
            "Epoch 498/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 23.8771 - mae: 3.3136 - learning_rate: 6.9253e-04\n",
            "Epoch 499/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 23.4343 - mae: 3.2811 - learning_rate: 6.9253e-04\n",
            "Epoch 500/500\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - loss: 23.8995 - mae: 3.3253 - learning_rate: 6.9253e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_accuracy(y_true, y_pred, tolerance=0.1):\n",
        "    # Calculate the absolute difference between predictions and true values\n",
        "    diff = tf.abs(y_true - y_pred)\n",
        "    # Check if the difference is within the tolerance level for each prediction\n",
        "    within_tolerance = tf.less_equal(diff, tolerance * y_true)\n",
        "    # Calculate mean accuracy across all dimensions\n",
        "    return tf.reduce_mean(tf.cast(within_tolerance, tf.float32))\n",
        "\n",
        "# Compile model with the custom accuracy metric\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae', custom_accuracy])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot loss\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot mean absolute error (MAE)\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(history.history['mae'], label='Mean Absolute Error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MAE')\n",
        "plt.title('Training MAE')\n",
        "plt.legend()\n",
        "\n",
        "# Plot custom accuracy (if defined)\n",
        "if 'custom_accuracy' in history.history:\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(history.history['custom_accuracy'], label='Custom Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SnTmFlbwX1ax",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "7a66a1cd-5339-45f9-9ed0-3eae205b692c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Cargar el modelo previamente guardado\n",
        "model = tf.keras.models.load_model(\"model_1.keras\", custom_objects={'custom_accuracy': custom_accuracy})\n",
        "\n",
        "# Preparar los datos de prueba\n",
        "testA_data = testA_subject_to_photo_df.merge(testA_hwg_metadata_df, on='subject_id').merge(testA_measurements_df, on='subject_id')\n",
        "testA_data['frontal_image_path'] = testA_mask_dir + '/' + testA_data['photo_id'] + '.png'\n",
        "testA_data['lateral_image_path'] = testA_mask_left_dir + '/' + testA_data['photo_id'] + '.png'\n",
        "\n",
        "# Generar predicciones\n",
        "predictions = []\n",
        "for _, row in testA_data.iterrows():\n",
        "    if os.path.exists(row['frontal_image_path']) and os.path.exists(row['lateral_image_path']):\n",
        "        frontal_image = tf.keras.preprocessing.image.load_img(row['frontal_image_path'], target_size=(224, 224), color_mode='grayscale')\n",
        "        lateral_image = tf.keras.preprocessing.image.load_img(row['lateral_image_path'], target_size=(224, 224), color_mode='grayscale')\n",
        "\n",
        "        # Convertir a arrays y concatenar en un input de 2 canales\n",
        "        frontal_image = tf.keras.preprocessing.image.img_to_array(frontal_image)\n",
        "        lateral_image = tf.keras.preprocessing.image.img_to_array(lateral_image)\n",
        "        combined_image = np.concatenate([frontal_image, lateral_image], axis=-1) / 255.0  # Normalizar\n",
        "\n",
        "        # Agregar height y weight como entradas adicionales\n",
        "        additional_inputs = np.array([[row['height_cm'], row['weight_kg']]], dtype=np.float32)\n",
        "\n",
        "        # Realizar la predicción\n",
        "        pred = model.predict([np.expand_dims(combined_image, axis=0), additional_inputs])\n",
        "        predictions.append([row['subject_id']] + pred[0].tolist())\n",
        "\n",
        "# Crear un DataFrame con las predicciones\n",
        "columns = ['subject_id', 'ankle', 'arm-length', 'bicep', 'calf', 'chest', 'forearm',\n",
        "           'height', 'hip', 'leg-length', 'shoulder-breadth', 'shoulder-to-crotch', 'thigh', 'waist', 'wrist']\n",
        "pred_df = pd.DataFrame(predictions, columns=columns)\n",
        "\n",
        "# Guardar las predicciones en un archivo CSV\n",
        "pred_df.to_csv('predictions_testA.csv', index=False)\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "CqgNGSiBDLcg",
        "outputId": "3bae70cf-334c-4155-9dc6-67475c5f46be"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The `{arg_name}` of this `Lambda` layer is a Python lambda. Deserializing it is unsafe. If you trust the source of the config artifact, you can override this error by passing `safe_mode=False` to `from_config()`, or calling `keras.config.enable_unsafe_deserialization().",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-0635e0bc4866>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Cargar el modelo previamente guardado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_1.keras\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'custom_accuracy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcustom_accuracy\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Preparar los datos de prueba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_zip\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_keras_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         return saving_lib.load_model(\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    235\u001b[0m             )\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             return _load_model_from_fileobj(\n\u001b[0m\u001b[1;32m    238\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36m_load_model_from_fileobj\u001b[0;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mconfig_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         model = _model_from_config(\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0mconfig_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36m_model_from_config\u001b[0;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;31m# Construct the model from the configuration file in the archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mObjectSharingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         model = deserialize_keras_object(\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcustom_obj_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             return functional_from_config(\n\u001b[0m\u001b[1;32m    522\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"layers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m    459\u001b[0m             )\n\u001b[1;32m    460\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             layer = serialization_lib.deserialize_keras_object(\n\u001b[0m\u001b[1;32m    462\u001b[0m                 \u001b[0mlayer_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcustom_obj_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/lambda_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects, safe_mode)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mfn_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__lambda__\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         ):\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_for_lambda_deserialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"function\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0minner_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             fn = python_utils.func_load(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/lambda_layer.py\u001b[0m in \u001b[0;36m_raise_for_lambda_deserialization\u001b[0;34m(arg_name, safe_mode)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raise_for_lambda_deserialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    173\u001b[0m                 \u001b[0;34m\"The `{arg_name}` of this `Lambda` layer is a Python lambda. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;34m\"Deserializing it is unsafe. If you trust the source of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The `{arg_name}` of this `Lambda` layer is a Python lambda. Deserializing it is unsafe. If you trust the source of the config artifact, you can override this error by passing `safe_mode=False` to `from_config()`, or calling `keras.config.enable_unsafe_deserialization()."
          ]
        }
      ]
    }
  ]
}